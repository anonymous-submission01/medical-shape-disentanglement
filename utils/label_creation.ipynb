{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430c33d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "obj_dir = Path('[path to mesh folder: minimal_scaled_obj_files]')\n",
        "metadata_csv = Path('[path to metadata file]')\n",
        "volume_csv = Path('[path to metadata file]')\n",
        "output_path = obj_dir / 'labels.pt'\n",
        "\n",
        "print(f\"OBJ directory: {obj_dir}\")\n",
        "print(f\"Metadata CSV: {metadata_csv}\")\n",
        "print(f\"Volume CSV: {volume_csv}\")\n",
        "print(f\"Output path: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d854baf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata files\n",
        "metadata_df = pd.read_csv(metadata_csv)\n",
        "volume_df = pd.read_csv(volume_csv)\n",
        "\n",
        "print(f\"Metadata shape: {metadata_df.shape}\")\n",
        "print(f\"Volume data shape: {volume_df.shape}\")\n",
        "print(\"\\nMetadata columns:\", metadata_df.columns.tolist())\n",
        "print(\"\\nVolume data columns:\", volume_df.columns.tolist())\n",
        "print(\"\\nMetadata sample:\")\n",
        "print(metadata_df.head())\n",
        "print(\"\\nVolume data sample:\")\n",
        "print(volume_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3614e050",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all combined hippocampus OBJ files\n",
        "obj_files = sorted([f.name for f in obj_dir.glob('*.obj') if 'combined' in f.name.lower()])\n",
        "print(f\"Found {len(obj_files)} combined hippocampus OBJ files\")\n",
        "print(\"\\nSample filenames:\")\n",
        "for i in range(min(5, len(obj_files))):\n",
        "    print(obj_files[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f71f863",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract subject_id and image_id from filename\n",
        "# Example: ADNI_002_S_0295_MR_Hippocampal_Mask_Hi_20080228111448800_S13408_I93328_combined.obj\n",
        "# Pattern: ADNI_{subject_id}_MR_..._{series_id}_{image_id}_combined.obj\n",
        "\n",
        "def parse_filename(filename):\n",
        "    \"\"\"\n",
        "    Extract subject_id and image_id from ADNI filename.\n",
        "    Returns (subject_id, image_id) or (None, None) if parsing fails.\n",
        "    \"\"\"\n",
        "    # Match pattern like: ADNI_002_S_0295_MR_..._I93328_combined.obj\n",
        "    pattern = r'ADNI_(\\d+_S_\\d+)_.*_I(\\d+)_combined\\.obj'\n",
        "    match = re.search(pattern, filename)\n",
        "    \n",
        "    if match:\n",
        "        subject_id = match.group(1)\n",
        "        image_id = match.group(2)\n",
        "        return subject_id, image_id\n",
        "    return None, None\n",
        "\n",
        "# Test parsing\n",
        "print(\"Testing filename parsing:\")\n",
        "for i in range(min(5, len(obj_files))):\n",
        "    fname = obj_files[i]\n",
        "    subj, img = parse_filename(fname)\n",
        "    print(f\"{fname} -> subject: {subj}, image: {img}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5140c491",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create mapping from image_id to metadata\n",
        "# Assuming metadata has 'image_id' and volume data has 'image_id' columns\n",
        "\n",
        "# Check what columns exist for matching\n",
        "print(\"Checking for matching columns...\")\n",
        "print(f\"Metadata columns with 'image' or 'id': {[c for c in metadata_df.columns if 'image' in c.lower() or 'id' in c.lower()]}\")\n",
        "print(f\"Volume columns with 'image' or 'id': {[c for c in volume_df.columns if 'image' in c.lower() or 'id' in c.lower()]}\")\n",
        "print(f\"Volume columns with 'hippo' or 'volume': {[c for c in volume_df.columns if 'hippo' in c.lower() or 'volume' in c.lower()]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069413dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create labels dictionary\n",
        "labels = {}\n",
        "missing_metadata = []\n",
        "missing_volume = []\n",
        "successfully_processed = []\n",
        "\n",
        "# Map diagnosis to binary: CN=0, AD=1\n",
        "diagnosis_map = {'CN': 0, 'AD': 1}\n",
        "\n",
        "# Map sex to numeric: M=0, F=1\n",
        "sex_map = {'M': 0, 'F': 1}\n",
        "\n",
        "def normalize_image_id(value):\n",
        "    s = str(value)\n",
        "    return s[1:] if s.startswith('I') else s\n",
        "\n",
        "for fname in obj_files:\n",
        "    base_name = fname.replace('.obj', '')\n",
        "    subject_id, image_id = parse_filename(fname)\n",
        "\n",
        "    if subject_id is None or image_id is None:\n",
        "        print(f\"Warning: Could not parse filename {fname}\")\n",
        "        continue\n",
        "\n",
        "    image_id_norm = normalize_image_id(image_id)\n",
        "\n",
        "    # Match with metadata (use subject_id and potentially image_id)\n",
        "    subject_metadata = metadata_df[metadata_df['subject_id'] == subject_id]\n",
        "\n",
        "    if len(subject_metadata) == 0:\n",
        "        missing_metadata.append(fname)\n",
        "        continue\n",
        "\n",
        "    # If there are multiple rows for a subject, try to match by image_id\n",
        "    if 'image_data_id' in subject_metadata.columns:\n",
        "        image_metadata = subject_metadata[\n",
        "            subject_metadata['image_data_id'].astype(str).map(normalize_image_id) == image_id_norm\n",
        "        ]\n",
        "        if len(image_metadata) > 0:\n",
        "            subject_metadata = image_metadata\n",
        "\n",
        "    # Take the first matching row\n",
        "    metadata_row = subject_metadata.iloc[0]\n",
        "\n",
        "    # Extract diagnosis, age, sex\n",
        "    diagnosis_str = metadata_row.get('diagnosis', 'MCI')  # Default to MCI if missing\n",
        "    diagnosis = diagnosis_map.get(diagnosis_str, -1)  # -1 for MCI or unknown\n",
        "\n",
        "    age = metadata_row.get('age', float('nan'))\n",
        "    sex_str = metadata_row.get('gender', None)\n",
        "\n",
        "    # Match with volume data\n",
        "    volume_match = volume_df[volume_df['subject_id'] == subject_id]\n",
        "\n",
        "    if 'image_uid' in volume_df.columns:\n",
        "        volume_match = volume_match[volume_match['image_uid'].astype(str) == image_id_norm]\n",
        "\n",
        "    if (sex_str is None or str(sex_str).strip() == '' or str(sex_str).upper() == 'U') and len(volume_match) > 0:\n",
        "        sex_str = volume_match.iloc[0].get('subject_sex', 'U')\n",
        "\n",
        "    sex = sex_map.get(str(sex_str).strip().upper(), -1)\n",
        "\n",
        "    if len(volume_match) == 0:\n",
        "        missing_volume.append(fname)\n",
        "        volume = float('nan')\n",
        "    else:\n",
        "        volume_row = volume_match.iloc[0]\n",
        "        # Look for combined hippocampus volume column\n",
        "        volume_col = [c for c in volume_df.columns if 'total' in c.lower() and 'hippo' in c.lower()]\n",
        "        if len(volume_col) > 0:\n",
        "            volume = volume_row.get(volume_col[0], float('nan'))\n",
        "        else:\n",
        "            volume = float('nan')\n",
        "\n",
        "    # Create label tensor: [diagnosis, age, sex, volume]\n",
        "    label = torch.tensor([diagnosis, age, sex, volume], dtype=torch.float32)\n",
        "    labels[base_name] = label\n",
        "    successfully_processed.append(fname)\n",
        "\n",
        "print(f\"\\nProcessing summary:\")\n",
        "print(f\"Total OBJ files: {len(obj_files)}\")\n",
        "print(f\"Successfully processed: {len(successfully_processed)}\")\n",
        "print(f\"Missing metadata: {len(missing_metadata)}\")\n",
        "print(f\"Missing volume data: {len(missing_volume)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4edffda",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample labels\n",
        "print(\"\\nSample labels:\")\n",
        "for i, (key, value) in enumerate(labels.items()):\n",
        "    if i < 10:\n",
        "        print(f\"{key}: {value.tolist()} (diagnosis={value[0]}, age={value[1]}, sex={value[2]}, volume={value[3]})\")\n",
        "    else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afde485b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save labels\n",
        "torch.save(labels, output_path)\n",
        "print(f\"\\nSaved {len(labels)} labels to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d842e51",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verification: Load and check saved labels\n",
        "loaded_labels = torch.load(output_path)\n",
        "print(f\"\\nVerification: Loaded {len(loaded_labels)} labels from {output_path}\")\n",
        "\n",
        "# Check a few random samples\n",
        "sample_keys = list(loaded_labels.keys())[:5]\n",
        "print(\"\\nVerifying sample labels:\")\n",
        "for key in sample_keys:\n",
        "    label = loaded_labels[key]\n",
        "    print(f\"{key}: diagnosis={label[0]}, age={label[1]}, sex={label[2]}, volume={label[3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "c85eb4c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Label statistics:\n",
            "Diagnosis distribution: CN=477, AD=342\n",
            "Age range: 55.0 - 91.0\n",
            "Age mean: 76.1\n",
            "Sex distribution: M=904, F=728\n",
            "Volume range: 1439.0 - 5936.4\n",
            "Volume mean: 3712.1\n"
          ]
        }
      ],
      "source": [
        "# Statistics\n",
        "all_labels_array = torch.stack(list(loaded_labels.values()))\n",
        "\n",
        "print(\"\\nLabel statistics:\")\n",
        "print(f\"Diagnosis distribution: CN={torch.sum(all_labels_array[:, 0] == 0).item()}, AD={torch.sum(all_labels_array[:, 0] == 1).item()}\")\n",
        "print(f\"Age range: {torch.min(all_labels_array[:, 1]):.1f} - {torch.max(all_labels_array[:, 1]):.1f}\")\n",
        "print(f\"Age mean: {torch.mean(all_labels_array[:, 1]):.1f}\")\n",
        "print(f\"Sex distribution: M={torch.sum(all_labels_array[:, 2] == 0).item()}, F={torch.sum(all_labels_array[:, 2] == 1).item()}\")\n",
        "print(f\"Volume range: {torch.min(all_labels_array[:, 3]):.1f} - {torch.max(all_labels_array[:, 3]):.1f}\")\n",
        "print(f\"Volume mean: {torch.mean(all_labels_array[:, 3]):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d3effe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-reference with split files to ensure all training/test files have labels\n",
        "import json\n",
        "\n",
        "split_dir = Path('../examples/splits/splits_combined_hippocampus_ADNI_No_MCI')\n",
        "train_split_file = split_dir / 'train_split_combined_hippocampus_adni_no_mci.json'\n",
        "test_split_file = split_dir / 'test_split_combined_hippocampus_adni_no_mci.json'\n",
        "val_split_file = split_dir / 'val_split_combined_hippocampus_adni_no_mci.json'\n",
        "\n",
        "if train_split_file.exists() and test_split_file.exists() and val_split_file.exists():\n",
        "    with open(train_split_file, 'r') as f:\n",
        "        train_files = json.load(f)\n",
        "    with open(test_split_file, 'r') as f:\n",
        "        test_files = json.load(f)\n",
        "    with open(val_split_file, 'r') as f:\n",
        "        val_files = json.load(f)\n",
        "    \n",
        "    all_split_files = train_files + test_files + val_files\n",
        "    missing_in_labels = []\n",
        "    \n",
        "    for fname in all_split_files:\n",
        "        base_name = fname.replace('.obj', '')\n",
        "        if base_name not in loaded_labels:\n",
        "            missing_in_labels.append(fname)\n",
        "    \n",
        "    print(f\"\\nSplit file verification:\")\n",
        "    print(f\"Total files in splits: {len(all_split_files)}\")\n",
        "    print(f\"Files in splits missing labels: {len(missing_in_labels)}\")\n",
        "    \n",
        "    if missing_in_labels:\n",
        "        print(\"\\nMissing labels for:\")\n",
        "        for fname in missing_in_labels[:10]:\n",
        "            print(f\"  {fname}\")\n",
        "else:\n",
        "    print(f\"\\nSplit files not found at {split_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1a239e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# AD vs CN combined hippocampus volume summary and box plot\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loaded_labels = torch.load(output_path, map_location='cpu')\n",
        "vols_by_diag = {0: [], 1: []}  # 0=CN, 1=AD\n",
        "for v in loaded_labels.values():\n",
        "    diag = int(v[0].item())\n",
        "    vol = float(v[3].item())\n",
        "    if diag in vols_by_diag and math.isfinite(vol):\n",
        "        vols_by_diag[diag].append(vol)\n",
        "\n",
        "cn_mean = np.mean(vols_by_diag[0])\n",
        "ad_mean = np.mean(vols_by_diag[1])\n",
        "print(f\"CN mean volume: {cn_mean:.2f}\")\n",
        "print(f\"AD mean volume: {ad_mean:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.boxplot([vols_by_diag[0], vols_by_diag[1]], labels=['CN', 'AD'], showmeans=True)\n",
        "plt.title('Combined Hippocampus Volume (AD vs CN)')\n",
        "plt.ylabel('Volume')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5af64a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# AD vs CN combined hippocampus volume summary and box plot\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loaded_labels = torch.load(output_path, map_location='cpu')\n",
        "vols_by_diag = {0: [], 1: []}  # 0=CN, 1=AD\n",
        "for v in loaded_labels.values():\n",
        "    diag = int(v[0].item())\n",
        "    vol = float(v[3].item())\n",
        "    if diag in vols_by_diag and math.isfinite(vol):\n",
        "        vols_by_diag[diag].append(vol)\n",
        "\n",
        "cn_mean = np.mean(vols_by_diag[0])\n",
        "ad_mean = np.mean(vols_by_diag[1])\n",
        "print(f\"CN mean volume: {cn_mean:.2f}\")\n",
        "print(f\"AD mean volume: {ad_mean:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.boxplot([vols_by_diag[0], vols_by_diag[1]], labels=['CN', 'AD'], showmeans=True)\n",
        "plt.title('Combined Hippocampus Volume (AD vs CN)')\n",
        "plt.ylabel('Volume')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d25a32d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# AD vs CN combined hippocampus volume summary and box plot\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loaded_labels = torch.load(output_path, map_location='cpu')\n",
        "vols_by_diag = {0: [], 1: []}  # 0=CN, 1=AD\n",
        "for v in loaded_labels.values():\n",
        "    diag = int(v[0].item())\n",
        "    vol = float(v[3].item())\n",
        "    if diag in vols_by_diag and math.isfinite(vol):\n",
        "        vols_by_diag[diag].append(vol)\n",
        "\n",
        "cn_mean = np.mean(vols_by_diag[0])\n",
        "ad_mean = np.mean(vols_by_diag[1])\n",
        "print(f\"CN mean volume: {cn_mean:.2f}\")\n",
        "print(f\"AD mean volume: {ad_mean:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.boxplot([vols_by_diag[0], vols_by_diag[1]], labels=['CN', 'AD'], showmeans=True)\n",
        "plt.title('Combined Hippocampus Volume (AD vs CN)')\n",
        "plt.ylabel('Volume')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2628048",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def count_outliers(vals):\n",
        "    vals = np.asarray(vals)\n",
        "    q1, q3 = np.percentile(vals, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
        "    mask = (vals < lo) | (vals > hi)\n",
        "    return mask.sum(), vals[mask], (lo, hi)\n",
        "\n",
        "cn_count, cn_vals, cn_bounds = count_outliers(vols_by_diag[0])\n",
        "ad_count, ad_vals, ad_bounds = count_outliers(vols_by_diag[1])\n",
        "\n",
        "print(f\"CN outliers: {cn_count} (bounds {cn_bounds})\")\n",
        "print(f\"AD outliers: {ad_count} (bounds {ad_bounds})\")\n",
        "# If you want the actual values:\n",
        "print(\"CN outlier values:\", cn_vals)\n",
        "print(\"AD outlier values:\", ad_vals)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "inr_sdf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
